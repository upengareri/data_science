{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Profitable Apps in Google and Apple Store\n",
    "\n",
    "Google and Apple app stores have millions of apps. Out of those millions of apps some are very famous and profitable while others are not. This project is about finding what makes an app profitable or which category of apps are more famous and profitable than others.\n",
    "\n",
    "The goal of this project is to get an understanding of what key points make an app successful. The project should give us an insight on which category apps are more famous so that the developers can get an idea of how to attract the users for their next app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    \"\"\"utility function to print dataset\"\"\"\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n')\n",
    "    if rows_and_columns:\n",
    "        print(\"Number of rows:    \", len(dataset))\n",
    "        print(\"Number of columns: \", len(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring Apple Dataset: \n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows:     7198\n",
      "Number of columns:  16\n"
     ]
    }
   ],
   "source": [
    "# create list of lists for both apple and google dataset\n",
    "from csv import reader\n",
    "with open(\"AppleStore.csv\", \"r\") as fp:\n",
    "    apple = reader(fp)\n",
    "    apple_data = list(apple)\n",
    "with open(\"googleplaystore.csv\", \"r\") as fp:\n",
    "    google = reader(fp)\n",
    "    google_data = list(google)\n",
    "    \n",
    "print(\"Exploring Apple Dataset: \\n\")\n",
    "explore_data(apple_data, 1, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple columns\n",
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "Google columns\n",
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n"
     ]
    }
   ],
   "source": [
    "print(\"Apple columns\")\n",
    "print(apple_data[0])\n",
    "print(\"\\n\")\n",
    "print(\"Google columns\")\n",
    "print(google_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Info on Datasets\n",
    "\n",
    "To get detailed information about the Google Play Store dataset, go to [Google dataset](https://www.kaggle.com/lava18/google-play-store-apps)\n",
    "\n",
    "Similarly, more info about Apple App Store dataset can be found at [Apple dataset](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "The process of preparing our data for analysis is calle __data cleaning__.\n",
    "It includes -\n",
    "* _deleting or correcting_ wrong data\n",
    "* _deleting_ duplicate data\n",
    "* _modifing_ data to fit our needs\n",
    "\n",
    "`It is said that Data Scientist spend 80% of their time cleaning the data and 20% of their time in analysing it.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting wrong data\n",
    "The google dataset has a dedicated [discussion section](https://www.kaggle.com/lava18/google-play-store-apps/discussion) and we can check that [one of the discussions](https://www.kaggle.com/lava18/google-play-store-apps/discussion/66015) suggest us about the wrong data row. We'll try to find out if it is actually wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Xposed Wi-Fi-Pwd', 'PERSONALIZATION', '3.5', '1042', '404k', '100,000+', 'Free', '0', 'Everyone', 'Personalization', 'August 5, 2014', '3.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n"
     ]
    }
   ],
   "source": [
    "print(google_data[10472])  # correct row\n",
    "print('\\n')\n",
    "print(google_data[0])  # header row\n",
    "print('\\n')\n",
    "print(google_data[10473])  # incorrect row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10842\n",
      "10841\n"
     ]
    }
   ],
   "source": [
    "# Looking at the kaggle discussion of the google dataset, we can see that the row at 10473 is missing some data points.\n",
    "print(len(google_data))\n",
    "del google_data[10473]\n",
    "print(len(google_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing duplicate entries\n",
    "__PART 1__\n",
    "\n",
    "By closing looking at the dataset, we can see that there are many duplicate entries. For instance, the app \"Instagram\" has four entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577446', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66509917', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n"
     ]
    }
   ],
   "source": [
    "for app in google_data:\n",
    "    name = app[0]\n",
    "    if name == \"Instagram\":\n",
    "        print(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of duplicate apps: 1181\n",
      "Length of unique apps: 9660\n",
      "\n",
      "\n",
      "Few examples of duplicate apps -\n",
      "['Quick PDF Scanner + OCR FREE', 'Box', 'Google My Business', 'ZOOM Cloud Meetings', 'join.me - Simple Meetings', 'Box', 'Zenefits', 'Google Ads', 'Google My Business', 'Slack', 'FreshBooks Classic', 'Insightly CRM', 'QuickBooks Accounting: Invoicing & Expenses', 'HipChat - Chat Built for Teams', 'Xero Accounting Software']\n"
     ]
    }
   ],
   "source": [
    "duplicate_apps = []\n",
    "unique_apps = []\n",
    "for app in google_data:\n",
    "    app_name = app[0]\n",
    "    if app_name in unique_apps:\n",
    "        duplicate_apps.append(app_name)\n",
    "    else:\n",
    "        unique_apps.append(app_name)\n",
    "        \n",
    "print(f\"Length of duplicate apps: {len(duplicate_apps)}\")\n",
    "print(f\"Length of unique apps: {len(unique_apps)}\")\n",
    "print(\"\\n\")\n",
    "print(\"Few examples of duplicate apps -\")\n",
    "print(duplicate_apps[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are total of duplicate 1181 apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the instagram duplicates we can find that the review column of it is not unique. The different values show that the data was collected at different times. We can use this criterion for keeping rows. We will not randomly delete the duplicate rows but keep only that row which has more reviews as they make more reliabile ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PART 2 __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
